{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import Data\nfrom keras.datasets import cifar100\n(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n","execution_count":26,"outputs":[{"output_type":"stream","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n169009152/169001437 [==============================] - 6s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize Data\nx_train = x_train.astype('float32')/255\nx_test = x_test.astype('float32')/255","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding\nfrom keras.utils import to_categorical\ny_train = to_categorical(y_train, 100)\ny_test = to_categorical(y_test, 100)\n","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define CNN\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu', input_shape = (32,32,3)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'\n                ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100, activation = \"softmax\"))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":34,"outputs":[{"output_type":"stream","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 16, 16, 32)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 16, 16, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 8, 8, 64)          0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 4096)              0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 512)               2097664   \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 100)               51300     \n=================================================================\nTotal params: 2,168,356\nTrainable params: 2,168,356\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Choosing Hyper-Parameters\nmodel.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Model\nmodel.fit(x_train, y_train, epochs=100, batch_size = 32)","execution_count":36,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 3.8677 - accuracy: 0.1130\nEpoch 2/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 3.2635 - accuracy: 0.2131\nEpoch 3/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 3.0147 - accuracy: 0.2598\nEpoch 4/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 2.8380 - accuracy: 0.2922\nEpoch 5/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 2.7213 - accuracy: 0.3127\nEpoch 6/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 2.6151 - accuracy: 0.3332\nEpoch 7/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 2.5264 - accuracy: 0.3518\nEpoch 8/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 2.4600 - accuracy: 0.3660\nEpoch 9/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 2.3927 - accuracy: 0.3762\nEpoch 10/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 2.3299 - accuracy: 0.3917\nEpoch 11/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 2.2849 - accuracy: 0.4029\nEpoch 12/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 2.2197 - accuracy: 0.4132\nEpoch 13/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 2.1712 - accuracy: 0.4247\nEpoch 14/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 2.1239 - accuracy: 0.4333\nEpoch 15/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 2.0757 - accuracy: 0.4443\nEpoch 16/100\n50000/50000 [==============================] - 74s 1ms/step - loss: 2.0551 - accuracy: 0.4503\nEpoch 17/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 2.0220 - accuracy: 0.4554\nEpoch 18/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.9825 - accuracy: 0.4636\nEpoch 19/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.9433 - accuracy: 0.4727\nEpoch 20/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.9282 - accuracy: 0.4758\nEpoch 21/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.8958 - accuracy: 0.4839\nEpoch 22/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.8602 - accuracy: 0.4939\nEpoch 23/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.8368 - accuracy: 0.4939\nEpoch 24/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.8128 - accuracy: 0.5016\nEpoch 25/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.7910 - accuracy: 0.5056\nEpoch 26/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.7799 - accuracy: 0.5104\nEpoch 27/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.7538 - accuracy: 0.5129\nEpoch 28/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.7380 - accuracy: 0.5198\nEpoch 29/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.7144 - accuracy: 0.5209\nEpoch 30/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.7076 - accuracy: 0.5290\nEpoch 31/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.6876 - accuracy: 0.5265\nEpoch 32/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.6589 - accuracy: 0.5379\nEpoch 33/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.6562 - accuracy: 0.5408\nEpoch 34/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.6297 - accuracy: 0.5435\nEpoch 35/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.6227 - accuracy: 0.5472\nEpoch 36/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.6007 - accuracy: 0.5529\nEpoch 37/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.5941 - accuracy: 0.5511\nEpoch 38/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.5787 - accuracy: 0.5554\nEpoch 39/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.5805 - accuracy: 0.5557\nEpoch 40/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.5474 - accuracy: 0.5637\nEpoch 41/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.5593 - accuracy: 0.5587\nEpoch 42/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.5332 - accuracy: 0.5676\nEpoch 43/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.5327 - accuracy: 0.5658\nEpoch 44/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.5232 - accuracy: 0.5712\nEpoch 45/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.5211 - accuracy: 0.5727\nEpoch 46/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.5145 - accuracy: 0.5729\nEpoch 47/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4893 - accuracy: 0.5776\nEpoch 48/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4878 - accuracy: 0.5780\nEpoch 49/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4764 - accuracy: 0.5808\nEpoch 50/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4664 - accuracy: 0.5851\nEpoch 51/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.4704 - accuracy: 0.5834\nEpoch 52/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4417 - accuracy: 0.5894\nEpoch 53/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4421 - accuracy: 0.5906\nEpoch 54/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4499 - accuracy: 0.5864\nEpoch 55/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.4314 - accuracy: 0.5939\nEpoch 56/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.4300 - accuracy: 0.5924\nEpoch 57/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4250 - accuracy: 0.5952\nEpoch 58/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4146 - accuracy: 0.6000\nEpoch 59/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4029 - accuracy: 0.6002\nEpoch 60/100\n50000/50000 [==============================] - 73s 1ms/step - loss: 1.3909 - accuracy: 0.6034\nEpoch 61/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.4064 - accuracy: 0.5988\nEpoch 62/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3985 - accuracy: 0.6030\nEpoch 63/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3979 - accuracy: 0.6035\nEpoch 64/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.3843 - accuracy: 0.6064\nEpoch 65/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3787 - accuracy: 0.6055\nEpoch 66/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.3738 - accuracy: 0.6057\nEpoch 67/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3767 - accuracy: 0.6084\nEpoch 68/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.3744 - accuracy: 0.6073\nEpoch 69/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.3668 - accuracy: 0.6104\nEpoch 70/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.3533 - accuracy: 0.6156\nEpoch 71/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.3426 - accuracy: 0.6168\nEpoch 72/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3487 - accuracy: 0.6135\nEpoch 73/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.3385 - accuracy: 0.6187\nEpoch 74/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3367 - accuracy: 0.6182\nEpoch 75/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3386 - accuracy: 0.6189\nEpoch 76/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3278 - accuracy: 0.6187\nEpoch 77/100\n","name":"stdout"},{"output_type":"stream","text":"50000/50000 [==============================] - 72s 1ms/step - loss: 1.3309 - accuracy: 0.6215\nEpoch 78/100\n50000/50000 [==============================] - 70s 1ms/step - loss: 1.3407 - accuracy: 0.6187\nEpoch 79/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3315 - accuracy: 0.6203\nEpoch 80/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3142 - accuracy: 0.6257\nEpoch 81/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.3081 - accuracy: 0.6265\nEpoch 82/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3130 - accuracy: 0.6239\nEpoch 83/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3147 - accuracy: 0.6262\nEpoch 84/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.2866 - accuracy: 0.6303\nEpoch 85/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.3068 - accuracy: 0.6261\nEpoch 86/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2967 - accuracy: 0.6293\nEpoch 87/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2907 - accuracy: 0.6304\nEpoch 88/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.2932 - accuracy: 0.6304\nEpoch 89/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.2807 - accuracy: 0.6353\nEpoch 90/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2842 - accuracy: 0.6326\nEpoch 91/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.2704 - accuracy: 0.6364\nEpoch 92/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2752 - accuracy: 0.6350\nEpoch 93/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2945 - accuracy: 0.6341\nEpoch 94/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2699 - accuracy: 0.6378\nEpoch 95/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2639 - accuracy: 0.6377\nEpoch 96/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.2649 - accuracy: 0.6362\nEpoch 97/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.2514 - accuracy: 0.6426\nEpoch 98/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2560 - accuracy: 0.6415\nEpoch 99/100\n50000/50000 [==============================] - 72s 1ms/step - loss: 1.2576 - accuracy: 0.6427\nEpoch 100/100\n50000/50000 [==============================] - 71s 1ms/step - loss: 1.2591 - accuracy: 0.6409\n","name":"stdout"},{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f4acc2975d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Results\nloss, accuracy = model.evaluate(x_test, y_test)\n\nprint(\"loss = \")\nprint(loss)\nprint(\"accuracy = \")\nprint (accuracy)","execution_count":37,"outputs":[{"output_type":"stream","text":"10000/10000 [==============================] - 3s 321us/step\nloss = \n2.6650347599029542\naccuracy = \n0.4097999930381775\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}